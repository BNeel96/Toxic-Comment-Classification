{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228f32ad",
   "metadata": {},
   "source": [
    "# RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3605063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2f735a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "351039d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8ff0cbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # exploring columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3a66989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,\"toxic\"].unique() # toxic column has only two uniue values i.e 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b9e78ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = list(df.iloc[:,2:].columns) # slicing based on index and storing only the column names\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0ba13307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>no_of_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>15294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>7877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  no_of_comments\n",
       "0          toxic           15294\n",
       "1   severe_toxic            1595\n",
       "2        obscene            8449\n",
       "3         threat             478\n",
       "4         insult            7877\n",
       "5  identity_hate            1405"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.iloc[:,2:] # slicing all rows from second column\n",
    "counts = []\n",
    "for i in categories: # iterating over the categories\n",
    "    counts.append((i, df1[i].sum()))    # appending the sum of 1's for each category in the 'counts' list of tuple\n",
    "\n",
    "data = pd.DataFrame(counts, columns=[\"category\", \"no_of_comments\"]) # converting a list to DataFrame\n",
    "data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f724e037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1      6360\n",
       "3      4209\n",
       "2      3480\n",
       "4      1760\n",
       "5       385\n",
       "6        31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 2:].sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "679bebc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(x=\"category\", y=\"no_of_comments\", kind=\"bar\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8853d15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowsums = df.iloc[:, 2:].sum(axis=1)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(rowsums.value_counts().reset_index()[\"index\"],rowsums.value_counts().reset_index()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3fd9b785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71998705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1      6360\n",
       "3      4209\n",
       "2      3480\n",
       "4      1760\n",
       "5       385\n",
       "6        31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsums.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c69d45e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j7/lj6rcbh97jx8htwtr1mk9km80000gn/T/ipykernel_44966/1358182564.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"comment_text\"] = df[\"comment_text\"].str.replace(\"\\d\",\"\")\n"
     ]
    }
   ],
   "source": [
    "df[\"comment_text\"] = df[\"comment_text\"].str.replace(\"\\d\",\"\")\n",
    "# The special character, \\d, matches any digit character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7d214218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleaning(text):\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"\\'ll\",\"will\", text)\n",
    "    text = re.sub(r\"\\'m\",\"am\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text) # replace consecutive whitespace characters using the regular expression \\s+\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text) # single characters are converted to ' '\n",
    "    # This regex expression states that match the text string for any alphabets from small a to small z or capital\n",
    "    # A to capital Z. Adding a + sign after ']' would indicate that string should have at least 1 character.\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "868e6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"comment_text\"] = df[\"comment_text\"].apply(cleaning) # Apply a function along an axis of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "61f27c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww  he matches this background colour iam s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man  iam really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i can not make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  d aww  he matches this background colour iam s...      0   \n",
       "2  000113f07ec002fd  hey man  iam really not trying to edit war  it...      0   \n",
       "3  0001b41b1c6bb37e    more i can not make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  you  sir  are my hero  any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c8df5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "list1 = stopwords.words(\"english\")\n",
    "list1.extend(['aa',\n",
    " 'aaa',\n",
    " 'aaaa',\n",
    " 'aaaaa',\n",
    " 'aaaaaaaa',\n",
    " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaany',\n",
    " 'aaaaaaaaaah',\n",
    " 'aaaaaaaaaahhhhhhhhhhhhhh',\n",
    " 'aaaaaaaaadm',\n",
    " 'aaaaaaaaaq',\n",
    " 'aaaaaaaacfo',\n",
    " 'aaaaaaaaczy',\n",
    " 'aaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
    " 'aaaaaaaari',\n",
    " 'aaaaaaaayui',\n",
    " 'aaaaaaahhhhhhhhhhhhhhhhhhhhhhhh',\n",
    " 'aaaaaaw',\n",
    " 'aaaaah',\n",
    " 'aaaah',\n",
    " 'aaaannnnyyyywwwwhhhheeeerrrreeee',\n",
    " 'aaaawwww',\n",
    " 'aaaboyz',\n",
    " 'aaages',\n",
    " 'aaaghh',\n",
    " 'aaah',\n",
    " 'aaahhh',\n",
    " 'aaahs',\n",
    " 'aaai',\n",
    " 'aaajade',\n",
    " 'aaand',\n",
    " 'aaarrrgggh',\n",
    " 'aaaww',\n",
    " 'aab',\n",
    " 'aaba',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f72595ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aaaaa',\n",
       " 'aaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaany',\n",
       " 'aaaaaaaaaah',\n",
       " 'aaaaaaaaaahhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaadm',\n",
       " 'aaaaaaaaaq',\n",
       " 'aaaaaaaacfo',\n",
       " 'aaaaaaaaczy',\n",
       " 'aaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaari',\n",
       " 'aaaaaaaayui',\n",
       " 'aaaaaaahhhhhhhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaw',\n",
       " 'aaaaah',\n",
       " 'aaaah',\n",
       " 'aaaannnnyyyywwwwhhhheeeerrrreeee',\n",
       " 'aaaawwww',\n",
       " 'aaaboyz',\n",
       " 'aaages',\n",
       " 'aaaghh',\n",
       " 'aaah',\n",
       " 'aaahhh',\n",
       " 'aaahs',\n",
       " 'aaai',\n",
       " 'aaajade',\n",
       " 'aaand',\n",
       " 'aaarrrgggh',\n",
       " 'aaaww',\n",
       " 'aab',\n",
       " 'aaba']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "59dc7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "46b1e965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x300475 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1017152 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "m2 = CountVectorizer(ngram_range=(1,2))\n",
    "ngram = m2.fit_transform(df[\"comment_text\"].values)\n",
    "ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a1723797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aa analysis', 'aa at', 'aa background', 'aa bt', 'aa does', 'aa for', 'aa giving']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(m2.get_feature_names()[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "16278f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  1  1 ...  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "count_values = ngram.toarray().sum(axis=0)\n",
    "print(count_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "966b0c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300475"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = m2.vocabulary_\n",
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e6f27de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': 86443,\n",
       " 'why': 287966,\n",
       " 'the': 248440,\n",
       " 'edits': 78457,\n",
       " 'made': 148472,\n",
       " 'under': 271171,\n",
       " 'my': 161715,\n",
       " 'username': 275233,\n",
       " 'hardcore': 107590,\n",
       " 'metallica': 155436,\n",
       " 'fan': 88522,\n",
       " 'were': 284264,\n",
       " 'reverted': 213458,\n",
       " 'they': 257622,\n",
       " 'weren': 284806,\n",
       " 'vandalisms': 276725,\n",
       " 'just': 136160,\n",
       " 'closure': 52749,\n",
       " 'on': 178112,\n",
       " 'some': 230020,\n",
       " 'gas': 99656,\n",
       " 'after': 5496,\n",
       " 'voted': 279689,\n",
       " 'at': 26311,\n",
       " 'new': 165635,\n",
       " 'york': 296872,\n",
       " 'dolls': 74237,\n",
       " 'fac': 87222,\n",
       " 'and': 12207,\n",
       " 'please': 193592,\n",
       " 'don': 74337,\n",
       " 'remove': 210335,\n",
       " 'template': 244332,\n",
       " 'from': 96891,\n",
       " 'talk': 242688,\n",
       " 'page': 186228,\n",
       " 'since': 226636,\n",
       " 'iam': 117825,\n",
       " 'retired': 213060,\n",
       " 'now': 171050,\n",
       " 'explanation why': 86489,\n",
       " 'why the': 288152,\n",
       " 'the edits': 250321,\n",
       " 'edits made': 78543,\n",
       " 'made under': 148669,\n",
       " 'under my': 271268,\n",
       " 'my username': 162570,\n",
       " 'username hardcore': 275248,\n",
       " 'hardcore metallica': 107595,\n",
       " 'metallica fan': 155437,\n",
       " 'fan were': 88554,\n",
       " 'were reverted': 284670,\n",
       " 'reverted they': 213521,\n",
       " 'they weren': 257984,\n",
       " 'weren vandalisms': 284828,\n",
       " 'vandalisms just': 276726,\n",
       " 'just closure': 136265,\n",
       " 'closure on': 52751,\n",
       " 'on some': 179162,\n",
       " 'some gas': 230259,\n",
       " 'gas after': 99657,\n",
       " 'after voted': 5710,\n",
       " 'voted at': 279691,\n",
       " 'at new': 26632,\n",
       " 'new york': 165934,\n",
       " 'york dolls': 296877,\n",
       " 'dolls fac': 74239,\n",
       " 'fac and': 87223,\n",
       " 'and please': 15035,\n",
       " 'please don': 193655,\n",
       " 'don remove': 74541,\n",
       " 'remove the': 210399,\n",
       " 'the template': 254332,\n",
       " 'template from': 244371,\n",
       " 'from the': 97625,\n",
       " 'the talk': 254281,\n",
       " 'talk page': 242965,\n",
       " 'page since': 186660,\n",
       " 'since iam': 226720,\n",
       " 'iam retired': 118056,\n",
       " 'retired now': 213068,\n",
       " 'aww': 28664,\n",
       " 'he': 109994,\n",
       " 'matches': 151778,\n",
       " 'this': 258756,\n",
       " 'background': 29075,\n",
       " 'colour': 53859,\n",
       " 'seemingly': 221437,\n",
       " 'stuck': 237826,\n",
       " 'with': 290715,\n",
       " 'thanks': 246030,\n",
       " 'january': 134201,\n",
       " 'utc': 275870,\n",
       " 'aww he': 28666,\n",
       " 'he matches': 110254,\n",
       " 'matches this': 151791,\n",
       " 'this background': 258873,\n",
       " 'background colour': 29081,\n",
       " 'colour iam': 53862,\n",
       " 'iam seemingly': 118066,\n",
       " 'seemingly stuck': 221450,\n",
       " 'stuck with': 237836,\n",
       " 'with thanks': 291786,\n",
       " 'thanks talk': 246171,\n",
       " 'talk january': 242888,\n",
       " 'january utc': 134225,\n",
       " 'hey': 112573,\n",
       " 'man': 150106,\n",
       " 'really': 206362,\n",
       " 'not': 168620,\n",
       " 'trying': 269062,\n",
       " 'to': 262466,\n",
       " 'edit': 77582,\n",
       " 'war': 280364,\n",
       " 'it': 131686,\n",
       " 'that': 246223,\n",
       " 'guy': 105903,\n",
       " 'is': 128574,\n",
       " 'constantly': 57958,\n",
       " 'removing': 210560,\n",
       " 'relevant': 209652,\n",
       " 'information': 124948,\n",
       " 'talking': 243129,\n",
       " 'me': 152785,\n",
       " 'through': 260940,\n",
       " 'instead': 125933,\n",
       " 'of': 172909,\n",
       " 'seems': 221453,\n",
       " 'care': 45961,\n",
       " 'more': 158757,\n",
       " 'about': 261,\n",
       " 'formatting': 95320,\n",
       " 'than': 245584,\n",
       " 'actual': 3031,\n",
       " 'info': 124770,\n",
       " 'hey man': 112634,\n",
       " 'man iam': 150154,\n",
       " 'iam really': 118045,\n",
       " 'really not': 206554,\n",
       " 'not trying': 170116,\n",
       " 'trying to': 269073,\n",
       " 'to edit': 263336,\n",
       " 'edit war': 77791,\n",
       " 'war it': 280432,\n",
       " 'it just': 132298,\n",
       " 'just that': 136752,\n",
       " 'that this': 248141,\n",
       " 'this guy': 259241,\n",
       " 'guy is': 105935,\n",
       " 'is constantly': 128980,\n",
       " 'constantly removing': 57979,\n",
       " 'removing relevant': 210600,\n",
       " 'relevant information': 209686,\n",
       " 'information and': 124960,\n",
       " 'and talking': 15927,\n",
       " 'talking to': 243149,\n",
       " 'to me': 264142,\n",
       " 'me through': 153272,\n",
       " 'through edits': 260974,\n",
       " 'edits instead': 78531,\n",
       " 'instead of': 125958,\n",
       " 'of my': 175136,\n",
       " 'my talk': 162518,\n",
       " 'page he': 186436,\n",
       " 'he seems': 110385,\n",
       " 'seems to': 221520,\n",
       " 'to care': 262867,\n",
       " 'care more': 45987,\n",
       " 'more about': 158758,\n",
       " 'about the': 975,\n",
       " 'the formatting': 250758,\n",
       " 'formatting than': 95335,\n",
       " 'than the': 245934,\n",
       " 'the actual': 248505,\n",
       " 'actual info': 3073,\n",
       " 'can': 44861,\n",
       " 'make': 149383,\n",
       " 'any': 17717,\n",
       " 'real': 206098,\n",
       " 'suggestions': 239717,\n",
       " 'improvement': 120837,\n",
       " 'wondered': 292638,\n",
       " 'if': 118799,\n",
       " 'section': 220633,\n",
       " 'statistics': 235871,\n",
       " 'should': 224798,\n",
       " 'be': 30919,\n",
       " 'later': 140915,\n",
       " 'or': 181470,\n",
       " 'subsection': 238701,\n",
       " 'types': 270102,\n",
       " 'accidents': 1972,\n",
       " 'think': 258365,\n",
       " 'references': 208378,\n",
       " 'may': 152319,\n",
       " 'need': 164460,\n",
       " 'tidying': 261398,\n",
       " 'so': 228781,\n",
       " 'are': 20234,\n",
       " 'all': 7710,\n",
       " 'in': 120924,\n",
       " 'exact': 85001,\n",
       " 'same': 217572,\n",
       " 'format': 95268,\n",
       " 'ie': 118759,\n",
       " 'date': 65029,\n",
       " 'etc': 83120,\n",
       " 'do': 73149,\n",
       " 'no': 166890,\n",
       " 'one': 179483,\n",
       " 'else': 79754,\n",
       " 'does': 73702,\n",
       " 'first': 91613,\n",
       " 'you': 296935,\n",
       " 'have': 108626,\n",
       " 'preferences': 197221,\n",
       " 'for': 93257,\n",
       " 'style': 238231,\n",
       " 'want': 280202,\n",
       " 'yourself': 299699,\n",
       " 'let': 142933,\n",
       " 'know': 138741,\n",
       " 'there': 256775,\n",
       " 'appears': 19193,\n",
       " 'backlog': 29123,\n",
       " 'articles': 23359,\n",
       " 'review': 213640,\n",
       " 'guess': 105416,\n",
       " 'delay': 67246,\n",
       " 'until': 272932,\n",
       " 'reviewer': 213778,\n",
       " 'turns': 269474,\n",
       " 'up': 273137,\n",
       " 'listed': 145520,\n",
       " 'form': 95167,\n",
       " 'eg': 78955,\n",
       " 'wikipedia': 288842,\n",
       " 'good': 103060,\n",
       " 'article': 22608,\n",
       " 'nominations': 167831,\n",
       " 'transport': 267741,\n",
       " 'more can': 158815,\n",
       " 'can not': 45117,\n",
       " 'not make': 169457,\n",
       " 'make any': 149390,\n",
       " 'any real': 18115,\n",
       " 'real suggestions': 206215,\n",
       " 'suggestions on': 239739,\n",
       " 'on improvement': 178646,\n",
       " 'improvement wondered': 120857,\n",
       " 'wondered if': 292641,\n",
       " 'if the': 119101,\n",
       " 'the section': 253724,\n",
       " 'section statistics': 220804,\n",
       " 'statistics should': 235888,\n",
       " 'should be': 224825,\n",
       " 'be later': 31658,\n",
       " 'later on': 140975,\n",
       " 'on or': 178920,\n",
       " 'or subsection': 182654,\n",
       " 'subsection of': 238704,\n",
       " 'of types': 176412,\n",
       " 'types of': 270109,\n",
       " 'of accidents': 172929,\n",
       " 'accidents think': 1974,\n",
       " 'think the': 258557,\n",
       " 'the references': 253356,\n",
       " 'references may': 208427,\n",
       " 'may need': 152434,\n",
       " 'need tidying': 164582,\n",
       " 'tidying so': 261399,\n",
       " 'so that': 229244,\n",
       " 'that they': 248135,\n",
       " 'they are': 257654,\n",
       " 'are all': 20269,\n",
       " 'all in': 7958,\n",
       " 'in the': 122637,\n",
       " 'the exact': 250500,\n",
       " 'exact same': 85022,\n",
       " 'same format': 217677,\n",
       " 'format ie': 95285,\n",
       " 'ie date': 118764,\n",
       " 'date format': 65057,\n",
       " 'format etc': 95281,\n",
       " 'etc can': 83147,\n",
       " 'can do': 44993,\n",
       " 'do that': 73428,\n",
       " 'that later': 247300,\n",
       " 'on if': 178636,\n",
       " 'if no': 118994,\n",
       " 'no one': 167312,\n",
       " 'one else': 179628,\n",
       " 'else does': 79780,\n",
       " 'does first': 73744,\n",
       " 'first if': 91720,\n",
       " 'if you': 119165,\n",
       " 'you have': 297516,\n",
       " 'have any': 108684,\n",
       " 'any preferences': 18095,\n",
       " 'preferences for': 197223,\n",
       " 'for formatting': 93788,\n",
       " 'formatting style': 95334,\n",
       " 'style on': 238278,\n",
       " 'on references': 179037,\n",
       " 'references or': 208438,\n",
       " 'or want': 182798,\n",
       " 'want to': 280291,\n",
       " 'to do': 263292,\n",
       " 'do it': 73290,\n",
       " 'it yourself': 133011,\n",
       " 'yourself please': 299764,\n",
       " 'please let': 193707,\n",
       " 'let me': 142975,\n",
       " 'me know': 153035,\n",
       " 'know there': 138907,\n",
       " 'there appears': 256797,\n",
       " 'appears to': 19218,\n",
       " 'to be': 262720,\n",
       " 'be backlog': 31042,\n",
       " 'backlog on': 29128,\n",
       " 'on articles': 178187,\n",
       " 'articles for': 23446,\n",
       " 'for review': 94408,\n",
       " 'review so': 213725,\n",
       " 'so guess': 228979,\n",
       " 'guess there': 105455,\n",
       " 'there may': 256937,\n",
       " 'may be': 152338,\n",
       " 'be delay': 31268,\n",
       " 'delay until': 67257,\n",
       " 'until reviewer': 272990,\n",
       " 'reviewer turns': 213788,\n",
       " 'turns up': 269478,\n",
       " 'up it': 273284,\n",
       " 'it listed': 132332,\n",
       " 'listed in': 145543,\n",
       " 'the relevant': 253393,\n",
       " 'relevant form': 209681,\n",
       " 'form eg': 95183,\n",
       " 'eg wikipedia': 78967,\n",
       " 'wikipedia good': 289081,\n",
       " 'good article': 103072,\n",
       " 'article nominations': 23039,\n",
       " 'nominations transport': 167844,\n",
       " 'sir': 227116,\n",
       " 'hero': 112420,\n",
       " 'chance': 48418,\n",
       " 'remember': 210171,\n",
       " 'what': 285038,\n",
       " 'you sir': 298107,\n",
       " 'sir are': 227118,\n",
       " 'are my': 20959,\n",
       " 'my hero': 162092,\n",
       " 'hero any': 112423,\n",
       " 'any chance': 17782,\n",
       " 'chance you': 48440,\n",
       " 'you remember': 297983,\n",
       " 'remember what': 210226,\n",
       " 'what page': 285356,\n",
       " 'page that': 186705,\n",
       " 'that on': 247553,\n",
       " 'congratulations': 57103,\n",
       " 'as': 23798,\n",
       " 'well': 283893,\n",
       " 'use': 274297,\n",
       " 'tools': 266281,\n",
       " 'congratulations from': 57108,\n",
       " 'from me': 97331,\n",
       " 'me as': 152828,\n",
       " 'as well': 25188,\n",
       " 'well use': 284141,\n",
       " 'use the': 274520,\n",
       " 'the tools': 254464,\n",
       " 'tools well': 266297,\n",
       " 'well talk': 284116,\n",
       " 'cocksucker': 53145,\n",
       " 'before': 33829,\n",
       " 'piss': 192675,\n",
       " 'around': 22256,\n",
       " 'work': 293101,\n",
       " 'cocksucker before': 53146,\n",
       " 'before you': 34059,\n",
       " 'you piss': 297858,\n",
       " 'piss around': 192676,\n",
       " 'around on': 22328,\n",
       " 'on my': 178849,\n",
       " 'my work': 162615,\n",
       " 'your': 298461,\n",
       " 'vandalism': 276566,\n",
       " 'matt': 152054,\n",
       " 'shirvington': 224401,\n",
       " 'has': 107863,\n",
       " 'been': 33171,\n",
       " 'again': 5765,\n",
       " 'will': 289824,\n",
       " 'banned': 29920,\n",
       " 'your vandalism': 299581,\n",
       " 'vandalism to': 276700,\n",
       " 'to the': 265189,\n",
       " 'the matt': 252039,\n",
       " 'matt shirvington': 152063,\n",
       " 'shirvington article': 224402,\n",
       " 'article has': 22883,\n",
       " 'has been': 107911,\n",
       " 'been reverted': 33635,\n",
       " 'reverted please': 213504,\n",
       " 'don do': 74419,\n",
       " 'it again': 131709,\n",
       " 'again or': 5911,\n",
       " 'or you': 182857,\n",
       " 'you will': 298376,\n",
       " 'will be': 289870,\n",
       " 'be banned': 31045,\n",
       " 'sorry': 231593,\n",
       " 'word': 292762,\n",
       " 'nonsense': 168109,\n",
       " 'was': 280886,\n",
       " 'offensive': 176957,\n",
       " 'anyway': 18651,\n",
       " 'intending': 126362,\n",
       " 'write': 294777,\n",
       " 'anything': 18505,\n",
       " 'wow': 294297,\n",
       " 'would': 293896,\n",
       " 'jump': 135960,\n",
       " 'merely': 154924,\n",
       " 'requesting': 211727,\n",
       " 'encyclopedic': 80774,\n",
       " 'school': 219396,\n",
       " 'reference': 208217,\n",
       " 'selective': 221739,\n",
       " 'breeding': 40407,\n",
       " 'but': 42110,\n",
       " 'almost': 8680,\n",
       " 'stub': 237774,\n",
       " 'points': 194340,\n",
       " 'animal': 16761,\n",
       " 'which': 286339,\n",
       " 'short': 224641,\n",
       " 'messy': 155352,\n",
       " 'gives': 101998,\n",
       " 'must': 161520,\n",
       " 'someone': 230763,\n",
       " 'expertise': 86278,\n",
       " 'eugenics': 83424,\n",
       " 'sorry if': 231641,\n",
       " 'the word': 255028,\n",
       " 'word nonsense': 292867,\n",
       " 'nonsense was': 168157,\n",
       " 'was offensive': 281603,\n",
       " 'offensive to': 176974,\n",
       " 'to you': 265492,\n",
       " 'you anyway': 297009,\n",
       " 'anyway iam': 18692,\n",
       " 'iam not': 118005,\n",
       " 'not intending': 169346,\n",
       " 'intending to': 126365,\n",
       " 'to write': 265480,\n",
       " 'write anything': 294785,\n",
       " 'anything in': 18562,\n",
       " 'the article': 248801,\n",
       " 'article wow': 23342,\n",
       " 'wow they': 294325,\n",
       " 'they would': 257998,\n",
       " 'would jump': 294057,\n",
       " 'jump on': 135968,\n",
       " 'on me': 178794,\n",
       " 'me for': 152946,\n",
       " 'for vandalism': 94695,\n",
       " 'vandalism iam': 276636,\n",
       " 'iam merely': 117992,\n",
       " 'merely requesting': 154976,\n",
       " 'requesting that': 211741,\n",
       " 'that it': 247208,\n",
       " 'it be': 131801,\n",
       " 'be more': 31758,\n",
       " 'more encyclopedic': 158923,\n",
       " 'encyclopedic so': 80793,\n",
       " 'so one': 229112,\n",
       " 'one can': 179549,\n",
       " 'can use': 45278,\n",
       " 'use it': 274428,\n",
       " 'it for': 132114,\n",
       " 'for school': 94440,\n",
       " 'school as': 219403,\n",
       " 'as reference': 24829,\n",
       " 'reference have': 208262,\n",
       " 'have been': 108718,\n",
       " 'been to': 33731,\n",
       " 'the selective': 253740,\n",
       " 'selective breeding': 221743,\n",
       " 'breeding page': 40410,\n",
       " 'page but': 186314,\n",
       " 'but it': 42386,\n",
       " 'it almost': 131721,\n",
       " 'almost stub': 8742,\n",
       " 'stub it': 237787,\n",
       " 'it points': 132532,\n",
       " 'points to': 194386,\n",
       " 'to animal': 262592,\n",
       " 'animal breeding': 16762,\n",
       " 'breeding which': 40412,\n",
       " 'which is': 286544,\n",
       " 'is short': 130449,\n",
       " 'short messy': 224670,\n",
       " 'messy article': 155354,\n",
       " 'article that': 23250,\n",
       " 'that gives': 247001,\n",
       " 'gives you': 102033,\n",
       " 'you no': 297781,\n",
       " 'no info': 167189,\n",
       " 'info there': 124838,\n",
       " 'there must': 256943,\n",
       " 'must be': 161533,\n",
       " 'be someone': 32151,\n",
       " 'someone around': 230775,\n",
       " 'around with': 22370,\n",
       " 'with expertise': 291069,\n",
       " 'expertise in': 86281,\n",
       " 'in eugenics': 121471,\n",
       " 'alignment': 7666,\n",
       " 'subject': 238427,\n",
       " 'contrary': 58978,\n",
       " 'those': 260091,\n",
       " 'dulithgow': 76234,\n",
       " 'alignment on': 7667,\n",
       " 'on this': 179246,\n",
       " 'this subject': 259807,\n",
       " 'subject and': 238431,\n",
       " 'and which': 16366,\n",
       " 'which are': 286369,\n",
       " 'are contrary': 20465,\n",
       " 'contrary to': 58992,\n",
       " 'to those': 265206,\n",
       " 'those of': 260222,\n",
       " 'of dulithgow': 173931,\n",
       " 'fair': 87922,\n",
       " 'rationale': 205047,\n",
       " 'image': 119657,\n",
       " 'wonju': 292676,\n",
       " 'jpg': 135631,\n",
       " 'uploading': 273669,\n",
       " 'notice': 170727,\n",
       " 'specifies': 233454,\n",
       " 'being': 34355,\n",
       " 'used': 274559,\n",
       " 'its': 133169,\n",
       " 'constitutes': 58023,\n",
       " 'addition': 3917,\n",
       " 'boilerplate': 38642,\n",
       " 'also': 9127,\n",
       " 'out': 184745,\n",
       " 'description': 68662,\n",
       " 'specific': 233241,\n",
       " 'using': 275534,\n",
       " 'each': 76762,\n",
       " 'consistent': 57833,\n",
       " 'go': 102388,\n",
       " 'include': 123168,\n",
       " 'uploaded': 273630,\n",
       " 'other': 183665,\n",
       " 'media': 153877,\n",
       " 'consider': 57529,\n",
       " 'checking': 49423,\n",
       " 'specified': 233439,\n",
       " 'pages': 186827,\n",
       " 'too': 265972,\n",
       " 'find': 91088,\n",
       " 'list': 145393,\n",
       " 'edited': 77820,\n",
       " 'by': 42868,\n",
       " 'clicking': 52473,\n",
       " 'contributions': 59176,\n",
       " 'link': 145018,\n",
       " 'located': 146422,\n",
       " 'very': 277953,\n",
       " 'top': 266310,\n",
       " 'when': 285654,\n",
       " 'logged': 146569,\n",
       " 'then': 256152,\n",
       " 'selecting': 221718,\n",
       " 'dropdown': 75858,\n",
       " 'box': 39862,\n",
       " 'note': 170430,\n",
       " 'images': 119899,\n",
       " 'lacking': 139957,\n",
       " 'such': 239010,\n",
       " 'an': 11155,\n",
       " 'deleted': 67384,\n",
       " 'week': 283567,\n",
       " 'described': 68613,\n",
       " 'criteria': 62675,\n",
       " 'speedy': 233607,\n",
       " 'deletion': 67587,\n",
       " 'questions': 203243,\n",
       " 'ask': 25417,\n",
       " 'them': 255769,\n",
       " 'copyright': 59955,\n",
       " 'thank': 246001,\n",
       " 'contribs': 59032,\n",
       " 'unspecified': 272868,\n",
       " 'source': 231893,\n",
       " 'noticed': 170812,\n",
       " 'file': 90576,\n",
       " 'currently': 63908,\n",
       " 'doesn': 73849,\n",
       " 'specify': 233457,\n",
       " 'who': 287189,\n",
       " 'created': 62102,\n",
       " 'content': 58436,\n",
       " 'status': 235927,\n",
       " 'unclear': 271001,\n",
       " 'did': 69935,\n",
       " 'create': 62027,\n",
       " 'owner': 185994,\n",
       " 'obtained': 172396,\n",
       " 'website': 283373,\n",
       " 'taken': 242444,\n",
       " 'together': 265659,\n",
       " 'restatement': 212726,\n",
       " 'terms': 244858,\n",
       " 'usually': 275784,\n",
       " 'sufficient': 239491,\n",
       " 'however': 116645,\n",
       " 'holder': 115144,\n",
       " 'different': 70529,\n",
       " 'publisher': 201868,\n",
       " 'their': 255171,\n",
       " 'acknowledged': 2545,\n",
       " 'adding': 3823,\n",
       " 'add': 3490,\n",
       " 'proper': 200287,\n",
       " 'licensing': 143600,\n",
       " 'tag': 242058,\n",
       " 'already': 8934,\n",
       " 'took': 266199,\n",
       " 'picture': 192272,\n",
       " 'audio': 27557,\n",
       " 'video': 278478,\n",
       " 'release': 209551,\n",
       " 'gfdl': 101463,\n",
       " 'believe': 34940,\n",
       " 'meets': 154206,\n",
       " 'tags': 242201,\n",
       " 'see': 220978,\n",
       " 'full': 98221,\n",
       " 'files': 90698,\n",
       " 'tagged': 242158,\n",
       " 'following': 92922,\n",
       " 'unsourced': 272827,\n",
       " 'untagged': 272916,\n",
       " 'copyrighted': 60050,\n",
       " 'non': 167864,\n",
       " 'free': 96333,\n",
       " 'license': 143531,\n",
       " 'per': 190089,\n",
       " 'hours': 116232,\n",
       " 'fair use': 87966,\n",
       " 'use rationale': 274480,\n",
       " 'rationale for': 205055,\n",
       " 'for image': 93914,\n",
       " 'image wonju': 119877,\n",
       " 'wonju jpg': 292677,\n",
       " 'jpg thanks': 135684,\n",
       " 'thanks for': 246078,\n",
       " 'for uploading': 94678,\n",
       " 'uploading image': 273673,\n",
       " 'jpg notice': 135672,\n",
       " 'notice the': 170769,\n",
       " 'the image': 251328,\n",
       " 'image page': 119807,\n",
       " 'page specifies': 186673,\n",
       " 'specifies that': 233456,\n",
       " 'that the': 248124,\n",
       " 'image is': 119765,\n",
       " 'is being': 128770,\n",
       " 'being used': 34807,\n",
       " 'used under': 274692,\n",
       " 'under fair': 271221,\n",
       " 'use but': 274334,\n",
       " 'but there': 42642,\n",
       " 'there is': 256913,\n",
       " 'is no': 129940,\n",
       " 'no explanation': 167112,\n",
       " 'explanation or': 86475,\n",
       " 'or rationale': 182477,\n",
       " 'rationale as': 205050,\n",
       " 'as to': 25095,\n",
       " 'to why': 265428,\n",
       " 'why its': 288068,\n",
       " 'its use': 133574,\n",
       " 'use in': 274419,\n",
       " 'in wikipedia': 122825,\n",
       " 'wikipedia articles': 288891,\n",
       " 'articles constitutes': 23409,\n",
       " 'constitutes fair': 58028,\n",
       " 'in addition': 120945,\n",
       " 'addition to': 3956,\n",
       " 'the boilerplate': 249125,\n",
       " 'boilerplate fair': 38643,\n",
       " 'use template': 274516,\n",
       " 'template you': 244441,\n",
       " 'you must': 297760,\n",
       " 'must also': 161526,\n",
       " 'also write': 9716,\n",
       " 'write out': 294838,\n",
       " 'out on': 184902,\n",
       " 'on the': 179232,\n",
       " 'image description': 119713,\n",
       " 'description page': 68678,\n",
       " 'page specific': 186671,\n",
       " 'specific explanation': 233280,\n",
       " 'for why': 94752,\n",
       " 'why using': 288170,\n",
       " 'using this': 275678,\n",
       " 'this image': 259301,\n",
       " 'image in': 119761,\n",
       " 'in each': 121422,\n",
       " 'each article': 76767,\n",
       " 'article is': 22930,\n",
       " 'is consistent': 128975,\n",
       " 'consistent with': 57845,\n",
       " 'with fair': 291081,\n",
       " 'use please': 274474,\n",
       " 'please go': 193682,\n",
       " 'go to': 102516,\n",
       " 'page and': 186264,\n",
       " 'and edit': 13390,\n",
       " 'edit it': 77678,\n",
       " 'it to': 132863,\n",
       " 'to include': 263811,\n",
       " 'include fair': 123199,\n",
       " 'rationale if': 205058,\n",
       " 'have uploaded': 109586,\n",
       " 'uploaded other': 273650,\n",
       " 'other fair': 183826,\n",
       " 'use media': 274442,\n",
       " 'media consider': 153892,\n",
       " 'consider checking': 57542,\n",
       " 'checking that': 49439,\n",
       " 'that you': 248376,\n",
       " 'have specified': 109487,\n",
       " 'specified the': 233449,\n",
       " 'the fair': 250577,\n",
       " 'rationale on': 205062,\n",
       " 'on those': 179248,\n",
       " 'those pages': 260230,\n",
       " 'pages too': 186983,\n",
       " 'too you': 266196,\n",
       " 'you can': 297144,\n",
       " 'can find': 45026,\n",
       " 'find list': 91160,\n",
       " 'list of': 145471,\n",
       " 'of image': 174510,\n",
       " 'image pages': 119808,\n",
       " 'pages you': 187016,\n",
       " 'have edited': 108908,\n",
       " 'edited by': 77833,\n",
       " 'by clicking': 43054,\n",
       " 'clicking on': 52475,\n",
       " 'the my': 252318,\n",
       " 'my contributions': 161904,\n",
       " 'contributions link': 59208,\n",
       " 'link it': 145071,\n",
       " 'it is': 132277,\n",
       " 'is located': 129765,\n",
       " 'located at': 146424,\n",
       " 'at the': 26761,\n",
       " 'the very': 254802,\n",
       " 'very top': 278225,\n",
       " 'top of': 266349,\n",
       " 'of any': 173068,\n",
       " 'any wikipedia': 18268,\n",
       " 'wikipedia page': 289235,\n",
       " 'page when': 186774,\n",
       " 'when you': 285987,\n",
       " 'you are': 297023,\n",
       " 'are logged': 20879,\n",
       " 'logged in': 146571,\n",
       " 'in and': 120992,\n",
       " 'and then': 15977,\n",
       " 'then selecting': 256463,\n",
       " 'selecting image': 221720,\n",
       " 'image from': 119737,\n",
       " 'the dropdown': 250242,\n",
       " 'dropdown box': 75859,\n",
       " 'box note': 39883,\n",
       " 'note that': 170508,\n",
       " 'that any': 246338,\n",
       " 'any fair': 17886,\n",
       " 'use images': 274418,\n",
       " 'images uploaded': 119978,\n",
       " 'uploaded after': 273631,\n",
       " 'after may': 5612,\n",
       " 'may and': 152327,\n",
       " 'and lacking': 14338,\n",
       " 'lacking such': 139965,\n",
       " 'such an': 239022,\n",
       " 'an explanation': 11571,\n",
       " 'explanation will': 86490,\n",
       " 'be deleted': 31269,\n",
       " 'deleted one': 67459,\n",
       " 'one week': 180017,\n",
       " 'week after': 283570,\n",
       " 'after they': 5697,\n",
       " 'they have': 257782,\n",
       " 'been uploaded': 33764,\n",
       " 'uploaded as': 273633,\n",
       " 'as described': 24099,\n",
       " 'described on': 68626,\n",
       " 'on criteria': 178366,\n",
       " 'criteria for': 62689,\n",
       " 'for speedy': 94517,\n",
       " 'speedy deletion': 233613,\n",
       " 'deletion if': 67645,\n",
       " 'any questions': 18111,\n",
       " 'questions please': 203299,\n",
       " 'please ask': 193608,\n",
       " 'ask them': 25481,\n",
       " 'them at': 255796,\n",
       " 'the media': 252065,\n",
       " 'media copyright': 153893,\n",
       " 'copyright questions': 60020,\n",
       " 'questions page': 203297,\n",
       " 'page thank': 186702,\n",
       " 'thank you': 246010,\n",
       " 'you talk': 298208,\n",
       " 'talk contribs': 242774,\n",
       " 'contribs unspecified': 59061,\n",
       " 'unspecified source': 272869,\n",
       " 'source for': 231962,\n",
       " 'jpg noticed': 135673,\n",
       " 'noticed that': 170832,\n",
       " 'the file': 250665,\n",
       " 'file description': 90598,\n",
       " 'page currently': 186351,\n",
       " 'currently doesn': 63931,\n",
       " 'doesn specify': 73960,\n",
       " 'specify who': 233467,\n",
       " 'who created': 287291,\n",
       " 'created the': 62181,\n",
       " 'the content': 249708,\n",
       " 'content so': 58543,\n",
       " 'so the': 229245,\n",
       " 'the copyright': 249755,\n",
       " 'copyright status': 60026,\n",
       " 'status is': 235955,\n",
       " 'is unclear': 130757,\n",
       " 'unclear if': 271012,\n",
       " 'you did': 297312,\n",
       " 'did not': 70060,\n",
       " 'not create': 168957,\n",
       " 'create this': 62093,\n",
       " 'this file': 259179,\n",
       " 'file yourself': 90661,\n",
       " 'yourself then': 299782,\n",
       " 'then you': 256568,\n",
       " 'will need': 290037,\n",
       " 'need to': 164584,\n",
       " 'to specify': 265025,\n",
       " 'specify the': 233463,\n",
       " 'the owner': 252669,\n",
       " 'owner of': 185999,\n",
       " 'of the': 176295,\n",
       " 'copyright if': 59980,\n",
       " 'you obtained': 297798,\n",
       " 'obtained it': 172402,\n",
       " 'it from': 132126,\n",
       " 'from website': 97702,\n",
       " 'website then': 283464,\n",
       " 'then link': 256358,\n",
       " 'link to': 145124,\n",
       " 'the website': 254914,\n",
       " 'website from': 283408,\n",
       " 'from which': 97714,\n",
       " 'which it': 286548,\n",
       " 'it was': 132944,\n",
       " 'was taken': 281929,\n",
       " 'taken together': 242503,\n",
       " 'together with': 265705,\n",
       " 'with restatement': 291625,\n",
       " 'restatement of': 212727,\n",
       " 'of that': 176293,\n",
       " 'that website': 248305,\n",
       " 'website terms': 283461,\n",
       " 'terms of': 244881,\n",
       " 'of use': 176485,\n",
       " 'use of': 274456,\n",
       " 'of its': 174639,\n",
       " 'its content': 133226,\n",
       " 'content is': 58497,\n",
       " 'is usually': 130830,\n",
       " 'usually sufficient': 275834,\n",
       " 'sufficient information': 239505,\n",
       " 'information however': 125017,\n",
       " 'however if': 116703,\n",
       " 'copyright holder': 59978,\n",
       " 'holder is': 115150,\n",
       " 'is different': 129136,\n",
       " 'different from': 70595,\n",
       " 'website publisher': 283445,\n",
       " 'publisher then': 201887,\n",
       " 'then their': 256510,\n",
       " 'their copyright': 255280,\n",
       " 'copyright should': 60024,\n",
       " 'should also': 224809,\n",
       " 'also be': 9180,\n",
       " 'be acknowledged': 30938,\n",
       " 'acknowledged as': 2547,\n",
       " 'well as': 283912,\n",
       " 'as adding': 23817,\n",
       " 'adding the': 3902,\n",
       " 'the source': 253981,\n",
       " 'source please': 232031,\n",
       " 'please add': 193597,\n",
       " 'add proper': 3595,\n",
       " 'proper copyright': 200306,\n",
       " 'copyright licensing': 59995,\n",
       " 'licensing tag': 143612,\n",
       " 'tag if': 242091,\n",
       " 'file doesn': 90602,\n",
       " 'doesn have': 73902,\n",
       " 'have one': 109244,\n",
       " 'one already': 179500,\n",
       " 'already if': 9007,\n",
       " 'you created': 297252,\n",
       " 'created took': 62189,\n",
       " 'took the': 266244,\n",
       " 'the picture': 252863,\n",
       " 'picture audio': 192278,\n",
       " 'audio or': 27563,\n",
       " 'or video': 182789,\n",
       " 'video then': 278527,\n",
       " 'then the': 256509,\n",
       " 'the tag': 254270,\n",
       " 'tag can': 242072,\n",
       " 'can be': 44915,\n",
       " 'be used': 32359,\n",
       " 'used to': 274690,\n",
       " 'to release': 264721,\n",
       " 'release it': 209566,\n",
       " 'it under': 132893,\n",
       " 'under the': 271313,\n",
       " 'the gfdl': 250918,\n",
       " 'gfdl if': 101465,\n",
       " 'you believe': 297092,\n",
       " 'believe the': 35000,\n",
       " 'media meets': 153918,\n",
       " 'meets the': 154217,\n",
       " 'the criteria': 249847,\n",
       " 'criteria at': 62682,\n",
       " 'at wikipedia': 26818,\n",
       " 'wikipedia fair': 289050,\n",
       " 'use use': 274538,\n",
       " 'use tag': 274513,\n",
       " 'tag such': 242115,\n",
       " 'such as': 239029,\n",
       " 'as or': 24658,\n",
       " 'or one': 182329,\n",
       " 'one of': 179793,\n",
       " 'the other': 252641,\n",
       " 'other tags': 184137,\n",
       " 'tags listed': 242220,\n",
       " 'listed at': 145530,\n",
       " 'wikipedia image': 289113,\n",
       " 'image copyright': 119698,\n",
       " 'copyright tags': 60031,\n",
       " 'tags fair': 242211,\n",
       " 'use see': 274495,\n",
       " 'see wikipedia': 221267,\n",
       " 'tags for': 242212,\n",
       " 'for the': 94594,\n",
       " 'the full': 250826,\n",
       " 'full list': 98262,\n",
       " 'of copyright': 173673,\n",
       " 'tags that': 242237,\n",
       " 'use if': 274416,\n",
       " 'other files': 183834,\n",
       " 'files consider': 90702,\n",
       " 'specified their': 233450,\n",
       " 'their source': 255660,\n",
       " 'source and': 231902,\n",
       " 'and tagged': 15921,\n",
       " 'tagged them': 242173,\n",
       " 'them too': 256020,\n",
       " 'of files': 174145,\n",
       " 'files you': 90719,\n",
       " 'uploaded by': 273636,\n",
       " 'by following': 43216,\n",
       " 'following this': 93015,\n",
       " 'this link': 259391,\n",
       " 'link unsourced': 145127,\n",
       " 'unsourced and': 272830,\n",
       " 'and untagged': 16196,\n",
       " 'untagged images': 272917,\n",
       " 'images may': 119940,\n",
       " 'been tagged': 33714,\n",
       " 'tagged as': 242161,\n",
       " 'is copyrighted': 129013,\n",
       " 'copyrighted under': 60064,\n",
       " ...}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a6f6f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.DataFrame(sorted([(count_values[j], i) for i, j in vocab.items()],reverse=True)).rename(columns={0:\"Frequency\",1:\"Unigram/Bigram\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5f3713e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Unigram/Bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31662</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18877</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14526</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14352</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14121</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300470</th>\n",
       "      <td>1</td>\n",
       "      <td>aa does</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300471</th>\n",
       "      <td>1</td>\n",
       "      <td>aa bt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300472</th>\n",
       "      <td>1</td>\n",
       "      <td>aa background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300473</th>\n",
       "      <td>1</td>\n",
       "      <td>aa at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300474</th>\n",
       "      <td>1</td>\n",
       "      <td>aa analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300475 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency Unigram/Bigram\n",
       "0           31662            the\n",
       "1           18877             to\n",
       "2           14526            you\n",
       "3           14352             of\n",
       "4           14121            and\n",
       "...           ...            ...\n",
       "300470          1        aa does\n",
       "300471          1          aa bt\n",
       "300472          1  aa background\n",
       "300473          1          aa at\n",
       "300474          1    aa analysis\n",
       "\n",
       "[300475 rows x 2 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "25942c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zzzz aftah',\n",
       " 'zzzz',\n",
       " 'zzyzwicz talk',\n",
       " 'zzyzwicz',\n",
       " 'zzpzza correct',\n",
       " 'zzpzza',\n",
       " 'zyzzyxrd will',\n",
       " 'zyzzyxrd',\n",
       " 'zyuranger dairanger',\n",
       " 'zyuranger',\n",
       " 'zwyke tak',\n",
       " 'zwyke',\n",
       " 'zweng die',\n",
       " 'zweng',\n",
       " 'zwack gb',\n",
       " 'zwack',\n",
       " 'zuwandte empoerte',\n",
       " 'zuwandte',\n",
       " 'zuse ideas',\n",
       " 'zuse as',\n",
       " 'zurich airport',\n",
       " 'zurich',\n",
       " 'zun derivative',\n",
       " 'zun',\n",
       " 'zumblito these',\n",
       " 'zumblito',\n",
       " 'zuma spending',\n",
       " 'zuma abused',\n",
       " 'zulu is',\n",
       " 'zulu',\n",
       " 'zukav significant',\n",
       " 'zukav',\n",
       " 'zuden and',\n",
       " 'zuden',\n",
       " 'zuckerbergs the',\n",
       " 'zuckerbergs',\n",
       " 'zuckerberg the',\n",
       " 'zuckerberg social',\n",
       " 'zuckerberg http',\n",
       " 'zuckerberg called',\n",
       " 'zuckerberg and',\n",
       " 'zuckerberg allegedly',\n",
       " 'zuck yeah',\n",
       " 'zuck yea',\n",
       " 'zuck they',\n",
       " 'zuck probably',\n",
       " 'zuck people',\n",
       " 'zuck just',\n",
       " 'zuck have',\n",
       " 'zuck ear',\n",
       " 'zuck dumb',\n",
       " 'zuck don',\n",
       " 'zubrin proposed',\n",
       " 'zubrin',\n",
       " 'zu sehen',\n",
       " 'zu schwarzenburg',\n",
       " 'zu not',\n",
       " 'zu for',\n",
       " 'ztar are',\n",
       " 'ztar',\n",
       " 'zrh vandal',\n",
       " 'zrh',\n",
       " 'zoroastrian priest',\n",
       " 'zoroastrian persians',\n",
       " 'zoroastrian origin',\n",
       " 'zoroastrian and',\n",
       " 'zoroaster adam',\n",
       " 'zoroaster',\n",
       " 'zordanlighter and',\n",
       " 'zordanlighter',\n",
       " 'zoraida active',\n",
       " 'zoraida',\n",
       " 'zora have',\n",
       " 'zora and',\n",
       " 'zootopia image',\n",
       " 'zootopia',\n",
       " 'zootalk',\n",
       " 'zoopro am',\n",
       " 'zoopro',\n",
       " 'zoomshare com',\n",
       " 'zoomshare',\n",
       " 'zoom ins',\n",
       " 'zoom',\n",
       " 'zoology which',\n",
       " 'zoology',\n",
       " 'zoologique et',\n",
       " 'zoologique',\n",
       " 'zoo tycoon',\n",
       " 'zoo and',\n",
       " 'zones he',\n",
       " 'zone would',\n",
       " 'zone utc',\n",
       " 'zone tab',\n",
       " 'zone it',\n",
       " 'zone guess',\n",
       " 'zondervan which',\n",
       " 'zondervan',\n",
       " 'zombies really',\n",
       " 'zombies by',\n",
       " 'zombiecronomicon distributed',\n",
       " 'zombiecronomicon',\n",
       " 'zohar hakadosh',\n",
       " 'zohar',\n",
       " 'zogby poll',\n",
       " 'zogby',\n",
       " 'zoe the',\n",
       " 'zoe stay',\n",
       " 'zodiacs show',\n",
       " 'zodiacs',\n",
       " 'zodiac stuff',\n",
       " 'zodiac ps',\n",
       " 'zodiac killer',\n",
       " 'zodiac can',\n",
       " 'zod user',\n",
       " 'zod like',\n",
       " 'zod and',\n",
       " 'zocky repeats',\n",
       " 'zocky',\n",
       " 'znet resource',\n",
       " 'znet',\n",
       " 'zmeczony jestem',\n",
       " 'zmeczony',\n",
       " 'zmarta and',\n",
       " 'zmarta',\n",
       " 'zman per',\n",
       " 'zman',\n",
       " 'zisser majid',\n",
       " 'zisser',\n",
       " 'zipcode los',\n",
       " 'zipcode',\n",
       " 'zip codes',\n",
       " 'zip archive',\n",
       " 'zionists the',\n",
       " 'zionists against',\n",
       " 'zionist you',\n",
       " 'zionist which',\n",
       " 'zionist version',\n",
       " 'zionist thinking',\n",
       " 'zionist state',\n",
       " 'zionist propaganda',\n",
       " 'zionist membership',\n",
       " 'zionist masquerading',\n",
       " 'zionist jew',\n",
       " 'zionist hatchet',\n",
       " 'zionist freak',\n",
       " 'zionist coming',\n",
       " 'zionism racism',\n",
       " 'zionism is',\n",
       " 'zionism go',\n",
       " 'zionism feb',\n",
       " 'zionism and',\n",
       " 'zion rangerz',\n",
       " 'zion ranger',\n",
       " 'zion page',\n",
       " 'zion in',\n",
       " 'zion assume',\n",
       " 'zion as',\n",
       " 'zinn what',\n",
       " 'zinn',\n",
       " 'zines talk',\n",
       " 'zines photo',\n",
       " 'zines little',\n",
       " 'zine stuff',\n",
       " 'zine',\n",
       " 'zindabad orlady',\n",
       " 'zindabad',\n",
       " 'zinc white',\n",
       " 'zinc',\n",
       " 'zimmerman presentism',\n",
       " 'zimmerman is',\n",
       " 'zimmerman in',\n",
       " 'zimmer ought',\n",
       " 'zimmer can',\n",
       " 'zimetbaum hi',\n",
       " 'zimetbaum and',\n",
       " 'zim closed',\n",
       " 'zim and',\n",
       " 'zig would',\n",
       " 'zig suzanne',\n",
       " 'zig jack',\n",
       " 'zig had',\n",
       " 'zicfaaaaibaj pg',\n",
       " 'zicfaaaaibaj',\n",
       " 'zibimix jockeys',\n",
       " 'zibimix',\n",
       " 'zi and',\n",
       " 'zi',\n",
       " 'zhi gucci',\n",
       " 'zhi',\n",
       " 'zheng ho',\n",
       " 'zheng',\n",
       " 'zhang work',\n",
       " 'zhang shows',\n",
       " 'zhang showed',\n",
       " 'zhang analysis',\n",
       " 'zh wikipedia',\n",
       " 'zh because',\n",
       " 'zh and',\n",
       " 'zeus jupiter',\n",
       " 'zeus as',\n",
       " 'zetterling',\n",
       " 'zet to',\n",
       " 'zet',\n",
       " 'zest uh',\n",
       " 'zest thanks',\n",
       " 'zervas his',\n",
       " 'zervas dear',\n",
       " 'zeroth law',\n",
       " 'zeroth',\n",
       " 'zero you',\n",
       " 'zero with',\n",
       " 'zero weight',\n",
       " 'zero tolerance',\n",
       " 'zero tangential',\n",
       " 'zero tag',\n",
       " 'zero subsequently',\n",
       " 'zero sites',\n",
       " 'zero responded',\n",
       " 'zero replace',\n",
       " 'zero reliable',\n",
       " 'zero reason',\n",
       " 'zero prior',\n",
       " 'zero point',\n",
       " 'zero once',\n",
       " 'zero my',\n",
       " 'zero maybe',\n",
       " 'zero is',\n",
       " 'zero indications',\n",
       " 'zero in',\n",
       " 'zero if',\n",
       " 'zero down',\n",
       " 'zero credibility',\n",
       " 'zero coverage',\n",
       " 'zero control',\n",
       " 'zero continues',\n",
       " 'zero babies',\n",
       " 'zero assumptions',\n",
       " 'zero asian',\n",
       " 'zero and',\n",
       " 'zero amount',\n",
       " 'zero am',\n",
       " 'zero also',\n",
       " 'zero affiliation',\n",
       " 'zereshk comment',\n",
       " 'zereshk',\n",
       " 'zephaniah written',\n",
       " 'zephaniah',\n",
       " 'zenwhat says',\n",
       " 'zenwhat is',\n",
       " 'zen and',\n",
       " 'zen am',\n",
       " 'zemun they',\n",
       " 'zemun',\n",
       " 'zell ravenheart',\n",
       " 'zell',\n",
       " 'zelda the',\n",
       " 'zelda far',\n",
       " 'zelaya pushing',\n",
       " 'zelaya',\n",
       " 'zeitgeist is',\n",
       " 'zeitgeist',\n",
       " 'zeisbergerbut remember',\n",
       " 'zeisbergerbut',\n",
       " 'zehtabi cos',\n",
       " 'zehtabi',\n",
       " 'zef stawinoga',\n",
       " 'zef',\n",
       " 'zeev sternhell',\n",
       " 'zeev',\n",
       " 'zeeland cities',\n",
       " 'zeeland',\n",
       " 'zedong was',\n",
       " 'zedong',\n",
       " 'zebra legs',\n",
       " 'zebra',\n",
       " 'zebedee said',\n",
       " 'zebedee ok',\n",
       " 'zeb colter',\n",
       " 'zeb',\n",
       " 'zealots wikipedia',\n",
       " 'zealots',\n",
       " 'zealot he',\n",
       " 'zealanders hands',\n",
       " 'zealanders',\n",
       " 'zealand wasn',\n",
       " 'zealand tv',\n",
       " 'zealand sue',\n",
       " 'zealand singer',\n",
       " 'zealand show',\n",
       " 'zealand may',\n",
       " 'zealand class',\n",
       " 'zealand and',\n",
       " 'zealand am',\n",
       " 'zeal both',\n",
       " 'zeal',\n",
       " 'ze made',\n",
       " 'ze',\n",
       " 'zdnet com',\n",
       " 'zdnet co',\n",
       " 'zdarza ale',\n",
       " 'zdarza',\n",
       " 'zaydra pena',\n",
       " 'zaydra',\n",
       " 'zassalete and',\n",
       " 'zassalete',\n",
       " 'zaroves history',\n",
       " 'zaroves',\n",
       " 'zarove has',\n",
       " 'zarove arbitration',\n",
       " 'zaragoza and',\n",
       " 'zaragoza',\n",
       " 'zar would',\n",
       " 'zar',\n",
       " 'zaqdmcxyc',\n",
       " 'zapruder contribution',\n",
       " 'zapruder',\n",
       " 'zapped regards',\n",
       " 'zapped',\n",
       " 'zapatancas you',\n",
       " 'zapatancas calling',\n",
       " 'zaostrog alone',\n",
       " 'zaostrog',\n",
       " 'zanjan province',\n",
       " 'zanjan',\n",
       " 'zangief edit',\n",
       " 'zangief',\n",
       " 'zambian from',\n",
       " 'zambian',\n",
       " 'zaloga got',\n",
       " 'zaloga',\n",
       " 'zalimun the',\n",
       " 'zalimun',\n",
       " 'zaky mallah',\n",
       " 'zaky',\n",
       " 'zakoni here',\n",
       " 'zakoni',\n",
       " 'zakir hussain',\n",
       " 'zaidan info',\n",
       " 'zaidan',\n",
       " 'zagreb the',\n",
       " 'zagreb pages',\n",
       " 'zagreb on',\n",
       " 'zagreb gelehrt',\n",
       " 'zagreb at',\n",
       " 'zagreb area',\n",
       " 'zag were',\n",
       " 'zag was',\n",
       " 'zag never',\n",
       " 'zag but',\n",
       " 'zafarnamah years',\n",
       " 'zadok des',\n",
       " 'zadok agree',\n",
       " 'zadar region',\n",
       " 'zadar littoral',\n",
       " 'zad won',\n",
       " 'zad',\n",
       " 'zacky vengeance',\n",
       " 'zacky',\n",
       " 'zachlumia terbounia',\n",
       " 'zachlumia most',\n",
       " 'zachlumia and',\n",
       " 'zacharias rhetor',\n",
       " 'zacharias',\n",
       " 'zacatecas la',\n",
       " 'zacatecas',\n",
       " 'zac efron',\n",
       " 'zaboravi al',\n",
       " 'zaboravi',\n",
       " 'yyyy mm',\n",
       " 'yyyy and',\n",
       " 'yyou have',\n",
       " 'yyou',\n",
       " 'yya or',\n",
       " 'yvesnimmo but',\n",
       " 'yvesnimmo',\n",
       " 'yuvraj singh',\n",
       " 'yuvraj',\n",
       " 'yussuf rahim',\n",
       " 'yussuf',\n",
       " 'yuri gagarin',\n",
       " 'yuri',\n",
       " 'yuppie skins',\n",
       " 'yuppie',\n",
       " 'yup wonder',\n",
       " 'yup will',\n",
       " 'yup we',\n",
       " 'yup she',\n",
       " 'yup communicator',\n",
       " 'yup belles',\n",
       " 'yunupingu northern',\n",
       " 'yunupingu',\n",
       " 'yunshui smalls',\n",
       " 'yunshui',\n",
       " 'yunshi sorry',\n",
       " 'yunshi',\n",
       " 'yunnie bubble',\n",
       " 'yunnie',\n",
       " 'yunnan as',\n",
       " 'yunnan',\n",
       " 'yunn requesting',\n",
       " 'yunn',\n",
       " 'yunis on',\n",
       " 'yunis accidentally',\n",
       " 'yunho changmin',\n",
       " 'yunho',\n",
       " 'yule yule',\n",
       " 'yule logs',\n",
       " 'yule itself',\n",
       " 'yuk no',\n",
       " 'yuk',\n",
       " 'yuje survey',\n",
       " 'yuje naming',\n",
       " 'yuin people',\n",
       " 'yuin',\n",
       " 'yuile and',\n",
       " 'yuile',\n",
       " 'yugoslavian league',\n",
       " 'yugoslavian cup',\n",
       " 'yugoslavia you',\n",
       " 'yugoslavia this',\n",
       " 'yugoslavia the',\n",
       " 'yugoslavia scholarly',\n",
       " 'yugoslavia occupation',\n",
       " 'yugoslavia in',\n",
       " 'yugoslavia does',\n",
       " 'yugoslav troops',\n",
       " 'yugoslav politics',\n",
       " 'yugoslav people',\n",
       " 'yugoslav nation',\n",
       " 'yugoslav media',\n",
       " 'yugoslav league',\n",
       " 'yugoslav football',\n",
       " 'yugoslav ethnically',\n",
       " 'yugoslav breakup',\n",
       " 'yuezhi ta',\n",
       " 'yuezhi sino',\n",
       " 'yuezhi meaning',\n",
       " 'yuezhi da',\n",
       " 'yuen lou',\n",
       " 'yuen lo',\n",
       " 'yue zhi',\n",
       " 'yue ti',\n",
       " 'yuck names',\n",
       " 'yuck',\n",
       " 'yucat where',\n",
       " 'yucat',\n",
       " 'yuan or',\n",
       " 'yuan and',\n",
       " 'yu yunn',\n",
       " 'yu',\n",
       " 'yt youtube',\n",
       " 'yt',\n",
       " 'ysearch org',\n",
       " 'ysearch',\n",
       " 'yrs there',\n",
       " 'yrs of',\n",
       " 'yrold it',\n",
       " 'yrfnciruak circumcision',\n",
       " 'yrfnciruak',\n",
       " 'yr which',\n",
       " 'yr old',\n",
       " 'yr it',\n",
       " 'yr htm',\n",
       " 'yr dyb',\n",
       " 'ypu pls',\n",
       " 'ypu',\n",
       " 'ypov this',\n",
       " 'ypov',\n",
       " 'youwill want',\n",
       " 'youwill use',\n",
       " 'youwill take',\n",
       " 'youwill soon',\n",
       " 'youwill reconsider',\n",
       " 'youwill realise',\n",
       " 'youwill quit',\n",
       " 'youwill pick',\n",
       " 'youwill participate',\n",
       " 'youwill observe',\n",
       " 'youwill not',\n",
       " 'youwill make',\n",
       " 'youwill lot',\n",
       " 'youwill lose',\n",
       " 'youwill likely',\n",
       " 'youwill like',\n",
       " 'youwill learn',\n",
       " 'youwill know',\n",
       " 'youwill just',\n",
       " 'youwill insist',\n",
       " 'youwill hear',\n",
       " 'youwill feel',\n",
       " 'youwill end',\n",
       " 'youwill check',\n",
       " 'youwill all',\n",
       " 'youve got',\n",
       " 'youve edited',\n",
       " 'youve been',\n",
       " 'youuuuuu terisoaio',\n",
       " 'youuuuuu',\n",
       " 'youtube with',\n",
       " 'youtube wile',\n",
       " 'youtube why',\n",
       " 'youtube was',\n",
       " 'youtube propaganda',\n",
       " 'youtube probably',\n",
       " 'youtube not',\n",
       " 'youtube is',\n",
       " 'youtube edition',\n",
       " 'youtube clips',\n",
       " 'youtube clip',\n",
       " 'youtube channel',\n",
       " 'youtube celebrity',\n",
       " 'youtube because',\n",
       " 'youtube as',\n",
       " 'youtube and',\n",
       " 'youtube all',\n",
       " 'youths these',\n",
       " 'youths listening',\n",
       " 'youthful underground',\n",
       " 'youthful',\n",
       " 'youth you',\n",
       " 'youth then',\n",
       " 'youth organisation',\n",
       " 'youth on',\n",
       " 'youth of',\n",
       " 'youth movement',\n",
       " 'youth member',\n",
       " 'youth mark',\n",
       " 'youth in',\n",
       " 'youth gun',\n",
       " 'youth gangs',\n",
       " 'youth folk',\n",
       " 'youth festival',\n",
       " 'youth federation',\n",
       " 'youth envy',\n",
       " 'youth cultures',\n",
       " 'youth accept',\n",
       " 'yourtransitad jpg',\n",
       " 'yourtransitad',\n",
       " 'yourslef have',\n",
       " 'yourslef',\n",
       " 'yourselves particularly',\n",
       " 'yourselves ii',\n",
       " 'yourselves if',\n",
       " 'yourselves and',\n",
       " 'yourselftoo bad',\n",
       " 'yourselftoo',\n",
       " 'yourself wrote',\n",
       " 'yourself will',\n",
       " 'yourself why',\n",
       " 'yourself while',\n",
       " 'yourself whether',\n",
       " 'yourself were',\n",
       " 'yourself wasn',\n",
       " 'yourself via',\n",
       " 'yourself very',\n",
       " 'yourself useful',\n",
       " 'yourself unlike',\n",
       " 'yourself unless',\n",
       " 'yourself twoofers',\n",
       " 'yourself tube',\n",
       " 'yourself trying',\n",
       " 'yourself thoroughly',\n",
       " 'yourself think',\n",
       " 'yourself they',\n",
       " 'yourself thats',\n",
       " 'yourself thanks',\n",
       " 'yourself talkcontribs',\n",
       " 'yourself suggest',\n",
       " 'yourself some',\n",
       " 'yourself simply',\n",
       " 'yourself several',\n",
       " 'yourself seriously',\n",
       " 'yourself see',\n",
       " 'yourself said',\n",
       " 'yourself richard',\n",
       " 'yourself reported',\n",
       " 'yourself prick',\n",
       " 'yourself person',\n",
       " 'yourself participate',\n",
       " 'yourself one',\n",
       " 'yourself of',\n",
       " 'yourself obvious',\n",
       " 'yourself north',\n",
       " 'yourself mormon',\n",
       " 'yourself maybe',\n",
       " 'yourself may',\n",
       " 'yourself like',\n",
       " 'yourself instead',\n",
       " 'yourself incidentally',\n",
       " 'yourself https',\n",
       " 'yourself http',\n",
       " 'yourself hi',\n",
       " 'yourself hey',\n",
       " 'yourself having',\n",
       " 'yourself have',\n",
       " 'yourself hate',\n",
       " 'yourself guarding',\n",
       " 'yourself green',\n",
       " 'yourself gger',\n",
       " 'yourself getting',\n",
       " 'yourself get',\n",
       " 'yourself gadfium',\n",
       " 'yourself from',\n",
       " 'yourself especially',\n",
       " 'yourself defined',\n",
       " 'yourself deeside',\n",
       " 'yourself cumshitter',\n",
       " 'yourself commodities',\n",
       " 'yourself book',\n",
       " 'yourself blocked',\n",
       " 'yourself bigger',\n",
       " 'yourself beforehand',\n",
       " 'yourself asswipe',\n",
       " 'yourself also',\n",
       " 'yourself all',\n",
       " 'yourself accordingly',\n",
       " 'yours without',\n",
       " 'yours wikipedia',\n",
       " 'yours whoops',\n",
       " 'yours where',\n",
       " 'yours ve',\n",
       " 'yours try',\n",
       " 'yours truly',\n",
       " 'yours to',\n",
       " 'yours they',\n",
       " 'yours there',\n",
       " 'yours that',\n",
       " 'yours thank',\n",
       " 'yours take',\n",
       " 'yours sincerly',\n",
       " 'yours see',\n",
       " 'yours right',\n",
       " 'yours poof',\n",
       " 'yours please',\n",
       " 'yours perhaps',\n",
       " 'yours or',\n",
       " 'yours oh',\n",
       " 'yours not',\n",
       " 'yours nadolig',\n",
       " 'yours my',\n",
       " 'yours later',\n",
       " 'yours its',\n",
       " 'yours in',\n",
       " 'yours hahaha',\n",
       " 'yours go',\n",
       " 'yours does',\n",
       " 'yours coloane',\n",
       " 'yours by',\n",
       " 'yours but',\n",
       " 'yours bu',\n",
       " 'yournumbertwofan',\n",
       " 'youre too',\n",
       " 'youre talking',\n",
       " 'youre right',\n",
       " 'youre on',\n",
       " 'youre horrible',\n",
       " 'youre here',\n",
       " 'youre graduate',\n",
       " 'youre good',\n",
       " 'youre faggot',\n",
       " 'youre edits',\n",
       " 'yourcousin',\n",
       " 'your zionist',\n",
       " 'your zapruder',\n",
       " 'your your',\n",
       " 'your young',\n",
       " 'your year',\n",
       " 'your yard',\n",
       " 'your xbox',\n",
       " 'your wrote',\n",
       " 'your writings',\n",
       " 'your wrists',\n",
       " 'your worthy',\n",
       " 'your working',\n",
       " 'your word',\n",
       " 'your wonderful',\n",
       " 'your womenfolks',\n",
       " 'your wmd',\n",
       " 'your wives',\n",
       " 'your withered',\n",
       " 'your witchhunt',\n",
       " 'your witch',\n",
       " 'your wishes',\n",
       " 'your wish',\n",
       " 'your wisdom',\n",
       " 'your windy',\n",
       " 'your win',\n",
       " 'your willing',\n",
       " 'your wikiproject',\n",
       " 'your wikipedian',\n",
       " 'your wikimedia',\n",
       " 'your well',\n",
       " 'your webpage',\n",
       " 'your weaknesses',\n",
       " 'your watchlists',\n",
       " 'your watchlist',\n",
       " 'your warped',\n",
       " 'your warnings',\n",
       " 'your wanting',\n",
       " 'your voice',\n",
       " 'your violation',\n",
       " 'your vendetta',\n",
       " 'your values',\n",
       " 'your valuable',\n",
       " 'your vaginas',\n",
       " 'your vagina',\n",
       " 'your usual',\n",
       " 'your using',\n",
       " 'your userpages',\n",
       " 'your usage',\n",
       " 'your unwarranted',\n",
       " 'your unsupported',\n",
       " 'your unreasonable',\n",
       " 'your unhistorical',\n",
       " 'your unfair',\n",
       " 'your underlying',\n",
       " 'your unconstructive',\n",
       " 'your unblocking',\n",
       " 'your ugly',\n",
       " 'your tyranny',\n",
       " 'your typical',\n",
       " 'your two',\n",
       " 'your trying',\n",
       " 'your troubles',\n",
       " 'your trollishness',\n",
       " 'your trollin',\n",
       " 'your treatment',\n",
       " 'your trash',\n",
       " 'your trail',\n",
       " 'your tracks',\n",
       " 'your topic',\n",
       " 'your tm',\n",
       " 'your title',\n",
       " 'your tips',\n",
       " 'your throat',\n",
       " 'your three',\n",
       " 'your thought',\n",
       " 'your thing',\n",
       " 'your thick',\n",
       " 'your theory',\n",
       " 'your text',\n",
       " 'your testicles',\n",
       " 'your testacles',\n",
       " 'your terms',\n",
       " 'your tenetuous',\n",
       " 'your tendentious',\n",
       " 'your tendancy',\n",
       " 'your ten',\n",
       " 'your temple',\n",
       " 'your templates',\n",
       " 'your temperament',\n",
       " 'your teeth',\n",
       " 'your teacher',\n",
       " 'your tags',\n",
       " 'your tagging',\n",
       " 'your tactics',\n",
       " 'your table',\n",
       " 'your systems',\n",
       " 'your system',\n",
       " 'your swearing',\n",
       " 'your surrender',\n",
       " 'your surface',\n",
       " 'your supporting',\n",
       " 'your supervisor',\n",
       " 'your super',\n",
       " 'your substitute',\n",
       " 'your substantial',\n",
       " 'your subpages',\n",
       " 'your subliminal',\n",
       " 'your subjective',\n",
       " 'your sub',\n",
       " 'your stupidity',\n",
       " 'your stupid',\n",
       " 'your study',\n",
       " 'your students',\n",
       " 'your stubs',\n",
       " 'your structure',\n",
       " 'your story',\n",
       " 'your stomach',\n",
       " 'your stature',\n",
       " 'your standards',\n",
       " 'your stalker',\n",
       " 'your spurious',\n",
       " 'your spiteful',\n",
       " 'your spiels',\n",
       " 'your speedy',\n",
       " 'your sorrows',\n",
       " 'your son',\n",
       " 'your some',\n",
       " 'your sockpuppets',\n",
       " 'your socialist',\n",
       " 'your soapbox',\n",
       " 'your so',\n",
       " 'your snide',\n",
       " 'your smug',\n",
       " 'your smile',\n",
       " 'your slimy',\n",
       " 'your sleeve',\n",
       " 'your sleep',\n",
       " 'your sku',\n",
       " 'your skirts',\n",
       " 'your skill',\n",
       " 'your sister',\n",
       " 'your sins',\n",
       " 'your sign',\n",
       " 'your sigismond',\n",
       " 'your sig',\n",
       " 'your shoulder',\n",
       " 'your should',\n",
       " 'your shit',\n",
       " 'your sexual',\n",
       " 'your seven',\n",
       " 'your serious',\n",
       " 'your serbo',\n",
       " 'your sentence',\n",
       " 'your sensibilities',\n",
       " 'your semen',\n",
       " 'your scripting',\n",
       " 'your screen',\n",
       " 'your screed',\n",
       " 'your scholarship',\n",
       " 'your scheduled',\n",
       " 'your say',\n",
       " 'your satisfaction',\n",
       " 'your sandbox',\n",
       " 'your sadass',\n",
       " 'your rss',\n",
       " 'your rsn',\n",
       " 'your romanticism',\n",
       " 'your rigid',\n",
       " 'your rightful',\n",
       " 'your ridiculous',\n",
       " 'your rfb',\n",
       " 'your revisions',\n",
       " 'your revision',\n",
       " 'your reviews',\n",
       " 'your reverting',\n",
       " 'your reversal',\n",
       " 'your revenge',\n",
       " 'your retroactive',\n",
       " 'your reticence',\n",
       " 'your resubmitting',\n",
       " 'your responsibilty',\n",
       " 'your responsibility',\n",
       " 'your reservations',\n",
       " 'your requests',\n",
       " 'your report',\n",
       " 'your replacement',\n",
       " 'your removed',\n",
       " 'your removals',\n",
       " 'your reluctance',\n",
       " 'your religious',\n",
       " 'your religion',\n",
       " 'your reliable',\n",
       " 'your relatives',\n",
       " 'your rejected',\n",
       " 'your rehab',\n",
       " 'your refs',\n",
       " 'your refactoring',\n",
       " 'your ref',\n",
       " 'your redirects',\n",
       " 'your reconstruction',\n",
       " 'your recommendation',\n",
       " 'your really',\n",
       " 'your reaction',\n",
       " 'your rationales',\n",
       " 'your rational',\n",
       " 'your rapidly',\n",
       " 'your randroide',\n",
       " 'your ramblings',\n",
       " 'your quotes',\n",
       " 'your quote',\n",
       " 'your query',\n",
       " 'your queries',\n",
       " 'your put',\n",
       " 'your pushing',\n",
       " 'your publications',\n",
       " 'your pseudo',\n",
       " 'your prov',\n",
       " 'your protest',\n",
       " 'your prosti',\n",
       " 'your proposition',\n",
       " 'your proposals',\n",
       " 'your proposal',\n",
       " 'your propagnadist',\n",
       " 'your profile',\n",
       " 'your product',\n",
       " 'your processes',\n",
       " 'your problems',\n",
       " 'your probably',\n",
       " 'your pro',\n",
       " 'your privileges',\n",
       " 'your priviledges',\n",
       " 'your privacy',\n",
       " 'your priority',\n",
       " 'your priorities',\n",
       " 'your primary',\n",
       " 'your pride',\n",
       " 'your pretty',\n",
       " 'your prerogative',\n",
       " 'your preparations',\n",
       " 'your preference',\n",
       " 'your preceding',\n",
       " 'your preaching',\n",
       " 'your pp',\n",
       " 'your povness',\n",
       " 'your pompus',\n",
       " 'your policies',\n",
       " 'your pipe',\n",
       " 'your picture',\n",
       " 'your phrases',\n",
       " 'your phrase',\n",
       " 'your personality',\n",
       " 'your persistent',\n",
       " 'your periodic',\n",
       " 'your people',\n",
       " 'your penis',\n",
       " 'your penchant',\n",
       " 'your peers',\n",
       " 'your pedofile',\n",
       " 'your peco',\n",
       " 'your peacekeeping',\n",
       " 'your pc',\n",
       " 'your pattern',\n",
       " 'your patients',\n",
       " 'your past',\n",
       " 'your pashtun',\n",
       " 'your party',\n",
       " 'your partisan',\n",
       " 'your parent',\n",
       " 'your panties',\n",
       " 'your pale',\n",
       " 'your pack',\n",
       " 'your overactive',\n",
       " 'your over',\n",
       " 'your os',\n",
       " 'your options',\n",
       " 'your oppose',\n",
       " 'your opionion',\n",
       " 'your opening',\n",
       " 'your oh',\n",
       " 'your official',\n",
       " 'your off',\n",
       " 'your odious',\n",
       " 'your obviously',\n",
       " 'your observations',\n",
       " 'your objections',\n",
       " 'your oath',\n",
       " 'your number',\n",
       " 'your npov',\n",
       " 'your notion',\n",
       " 'your noses',\n",
       " 'your nor',\n",
       " 'your nominations',\n",
       " 'your no',\n",
       " 'your nixonian',\n",
       " 'your nice',\n",
       " 'your newly',\n",
       " 'your newfound',\n",
       " 'your neurosis',\n",
       " 'your network',\n",
       " 'your neo',\n",
       " 'your negative',\n",
       " 'your near',\n",
       " 'your navigation',\n",
       " 'your naughtiness',\n",
       " 'your nation',\n",
       " 'your narrow',\n",
       " 'your narcissism',\n",
       " 'your names',\n",
       " 'your named',\n",
       " 'your naked',\n",
       " 'your musical',\n",
       " 'your mums',\n",
       " 'your moves',\n",
       " 'your move',\n",
       " 'your motto',\n",
       " 'your motions',\n",
       " 'your moral',\n",
       " 'your moother',\n",
       " 'your monobook',\n",
       " 'your monkey',\n",
       " 'your moms',\n",
       " 'your momk',\n",
       " 'your modest',\n",
       " 'your misue',\n",
       " 'your mistakes',\n",
       " 'your mistake',\n",
       " 'your mission',\n",
       " 'your misreading',\n",
       " 'your misinterpretation',\n",
       " 'your misinformation',\n",
       " 'your miserable',\n",
       " 'your misconception',\n",
       " 'your minds',\n",
       " 'your mileage',\n",
       " 'your methods',\n",
       " 'your mental',\n",
       " 'your men',\n",
       " 'your memory',\n",
       " ...]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d2[d2[\"Frequency\"]==1][\"Unigram/Bigram\"])\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "# Classification Specific to Text Data - About, Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "08aa9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"comment_text\"]\n",
    "Y = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0a5dc784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the model into 80% Train and 20% Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "19eccbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer(max_features=1000,\n",
    "               analyzer=\"word\",\n",
    "               stop_words=\"english\", norm=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b7013843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fit(data) method is used to compute the mean and std dev for a given feature to be used further for scaling.\n",
    "# The transform(data) method is used to perform scaling using mean and std dev calculated using the .fit() method.\n",
    "# The fit_transform() method does both fits and transform.\n",
    "xtrain_tfidf = model.fit_transform(xtrain)\n",
    "xtest_tfidf = model.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d0200ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 109794 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8830b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0db0a076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of \n",
    "# the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size \n",
    "# is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to \n",
    "# build each tree.\n",
    "\n",
    "a12 = RandomForestClassifier()\n",
    "model1 = MultiOutputClassifier(estimator= a12)\n",
    "model1.fit(xtrain_tfidf, ytrain)\n",
    "# When data is fitted with an estimator, parameters are estimated from the data at hand. \n",
    "# model.fit() : fit training data. For supervised learning applications, this accepts two arguments: the data X \n",
    "# and the labels y (e.g. model.fit(X, y)). For unsupervised learning applications, this accepts only a single \n",
    "# argument, the data X (e.g. model.fit(X))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f1788e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c6a9b752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bd511ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results\n",
      "toxic==> 0.995375\n",
      "severe_toxic==> 0.9985\n",
      "obscene==> 0.99825\n",
      "threat==> 0.999875\n",
      "insult==> 0.997\n",
      "identity_hate==> 0.999125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "pred = model1.predict(xtrain_tfidf)\n",
    "\n",
    "print(\"Training Results\")\n",
    "for i in range(len(list3)):\n",
    "    acc1 = accuracy_score(ytrain.iloc[:, i], pred[:,i])\n",
    "    print(list3[i]+ \"==>\", acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ecfe361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n",
      "toxic==> 0.936\n",
      "severe_toxic==> 0.9905\n",
      "obscene==> 0.9705\n",
      "threat==> 0.996\n",
      "insult==> 0.9645\n",
      "identity_hate==> 0.995\n"
     ]
    }
   ],
   "source": [
    "pred = model1.predict(xtest_tfidf)\n",
    "\n",
    "print(\"Test Results\")\n",
    "for i in range(len(list3)):\n",
    "    acc1 = accuracy_score(ytest.iloc[:, i], pred[:,i])\n",
    "    print(list3[i]+ \"==>\", acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c109b",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4f17b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ddadf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate           none  \n",
       "count  159571.000000  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805       0.898321  \n",
       "std         0.216627       0.093420       0.302226  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train['none'] = 1-train[label_cols].max(axis=1)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c8bb51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prepare a Term Matrix documentation on the basis of Training data.\n",
    "# Then we transform the test data on the basis of this matrix formed by the training data vocabulary.\n",
    "# n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(xtrain)\n",
    "test_term_doc = vec.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2881b90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<8000x33549 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 616629 stored elements in Compressed Sparse Row format>,\n",
       " <2000x33549 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 144344 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we print the Term Matrix Documentation for Training and Test Data \n",
    "# Here 159571 determines the number of rows/comments in the Training Data, while 426,005 determines the number of \n",
    "# unique words in the Training data\n",
    "trn_term_doc, test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "adfed95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5e0371a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results\n",
      "toxic => 0.99925\n",
      "severe_toxic => 0.99875\n",
      "obscene => 0.99975\n",
      "threat => 0.99925\n",
      "insult => 0.999375\n",
      "identity_hate => 0.999125\n"
     ]
    }
   ],
   "source": [
    "# import and instantiate the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression(C=12.0)\n",
    "print('Training Results')\n",
    "for label in label_cols:\n",
    "    y = ytrain[label]\n",
    "    logreg.fit(trn_term_doc, y)\n",
    "    y_pred_X = logreg.predict(trn_term_doc)\n",
    "    print(label,'=> {}'.format(accuracy_score(y, y_pred_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "174ef1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n",
      "toxic => 0.9095\n",
      "severe_toxic => 0.9925\n",
      "obscene => 0.9545\n",
      "threat => 0.9975\n",
      "insult => 0.955\n",
      "identity_hate => 0.995\n"
     ]
    }
   ],
   "source": [
    "print('Test Results')\n",
    "for label in label_cols:\n",
    "    y = ytest[label]\n",
    "    y_pred_X = logreg.predict(test_term_doc)\n",
    "    print(label,'=> {}'.format(accuracy_score(y, y_pred_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672a871",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0275ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "342f5a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = ytrain[list_classes].values\n",
    "list_sentences_train = xtrain\n",
    "list_sentences_test = xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fe121a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5273321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2_000 # Defining the maximum number of unique words in the dictionary.\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1c124974",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1403 # Fixing the length of each sentence to 1403 so we do not loose on useful features.\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "041e5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of the number of words in sentences.\n",
    "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d5388a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We see count of comments/instances on y axis as per the number of words in them.\n",
    "plt.hist(totalNumWords,bins = np.arange(0,410,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2a16902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2acd3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "# max_features - Size of the vocabulary\n",
    "# embed_size - Output size of the Comment (also Output Size of the Embedded Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2ba0a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required input dimensions=60\n",
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8803e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalMaxPool1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c6c8f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d946fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(50, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "86c5c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fe8540f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(6, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "384c7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cfd7fc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "225/225 [==============================] - 86s 374ms/step - loss: 0.2000 - accuracy: 0.5832 - val_loss: 0.1514 - val_accuracy: 0.9925\n",
      "Epoch 2/2\n",
      "225/225 [==============================] - 82s 362ms/step - loss: 0.1449 - accuracy: 0.7660 - val_loss: 0.1306 - val_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc9540ce80>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5df0c2b1",
   "metadata": {},
   "source": [
    "When we mention validation_split as fit parameter while fitting DL model, it splits data into two parts for every epoch i.e. training data and validation data. It trains the model on training data and validate the model on validation data by checking its loss and accuracy.\n",
    "\n",
    "Usually with every epoch increasing, loss goes lower and accuracy goes higher. But with val_loss and val_acc, many cases can be possible:\n",
    "\n",
    "val_loss starts increasing, val_acc starts decreasing(means model is cramming values not learning)\n",
    "val_loss starts increasing, val_acc also increases.(could be case of overfitting or diverse probability values in cases softmax is used in output layer)\n",
    "val_loss starts decreasing, val_acc starts increasing(Correct, means model build is learning and working fine)\n",
    "This is a link to refer as well in which there is more description given. Thanks. How to interpret \"loss\" and \"accuracy\" for a machine learning model\n",
    "\n",
    "I have tried to explain at https://www.javacodemonk.com/difference-between-loss-accuracy-validation-loss-validation-accuracy-when-training-deep-learning-model-with-keras-ff358faa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8ee65cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1403)]            0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 1403, 100)         200000    \n",
      "                                                                 \n",
      " lstm_layer (LSTM)           (None, 1403, 60)          38640     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 60)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                3050      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 306       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,996\n",
      "Trainable params: 241,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cd90b3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 9s 139ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred =model.predict(X_te, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4d63dbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08377764, 0.01279071, 0.04693026, 0.00334716, 0.04095143,\n",
       "        0.0082232 ],\n",
       "       [0.13934042, 0.01979189, 0.07248167, 0.00598521, 0.07342702,\n",
       "        0.01369744],\n",
       "       [0.09229115, 0.01348989, 0.04824023, 0.00390115, 0.04745666,\n",
       "        0.00846933],\n",
       "       ...,\n",
       "       [0.05461282, 0.00854694, 0.03409029, 0.00234724, 0.02751591,\n",
       "        0.00617564],\n",
       "       [0.05975499, 0.00993711, 0.03782484, 0.0027821 , 0.03053864,\n",
       "        0.00693227],\n",
       "       [0.07863412, 0.01203053, 0.04197321, 0.00354693, 0.03779859,\n",
       "        0.00794137]], dtype=float32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d0099f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_x_new = []\n",
    "for row in y_pred:\n",
    "    row_new = []\n",
    "    for j in range(len(row)):\n",
    "        if row[j] >= 0.5:\n",
    "            row_new.append(1)\n",
    "        else:\n",
    "            row_new.append(0)\n",
    "    y_pred_x_new.append(row_new)\n",
    "y_pred_x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d6980e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df.iloc[:, 2:]\n",
    "list3 = Y.columns\n",
    "list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3fe95b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [toxic, severe_toxic, obscene, threat, insult, identity_hate]\n",
       "Index: []"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_x_new_df=pd.DataFrame(columns=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate'])\n",
    "y_pred_x_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d1510e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y_pred_x_new:\n",
    "    y_pred_x_new_df.loc[len(y_pred_x_new_df.index)]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "11ba7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "90c8c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n",
      "toxic==> 0.909\n",
      "severe_toxic==> 0.993\n",
      "obscene==> 0.955\n",
      "threat==> 0.998\n",
      "insult==> 0.9555\n",
      "identity_hate==> 0.9945\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Results\")\n",
    "for i in range(len(list3)):\n",
    "    acc1 = accuracy_score(ytest.iloc[:, i], y_pred_x_new_df.iloc[:,i])\n",
    "    print(list3[i]+ \"==>\", acc1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
