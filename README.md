# Toxic-Comment-Classification - WIP

https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge

Build a model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.
